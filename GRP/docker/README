# Servicio gRPC de Predicción de Vinos

Este proyecto implementa un servicio gRPC para predicción de calidad de vinos utilizando Docker y Python.

## 📁 Estructura del Proyecto

```
GRP/
├── docker/
│   ├── Dockerfile
│   ├── requirements.txt
│   ├── buildAll.sh
│   ├── runAll.sh
│   └── stopAll.sh
├── src/
│   ├── grp_app.py
│   ├── test_client.py
│   ├── wine_service.proto
│   ├── wine_service_pb2.py
│   └── wine_service_pb2_grpc.py
└── models/
    └── random_forest_model.pkl
```

## 🛠️ Requisitos

- Docker
- Python 3.10+
- Modelo entrenado (`random_forest_model.pkl`)

## 🚀 Configuración y Despliegue

### 1. Construcción de la Imagen Docker

```bash
# Desde la raíz del proyecto
docker build -t microservicio-grpc:1.0 -f docker/Dockerfile .
```

### 2. Ejecución del Contenedor

```bash
docker run -d \
    --name wine-predictor \
    -p 50051:50051 \
    -v "$(pwd)/models:/app/models" \
    -e GRPC_PORT=50051 \
    -e MODEL_PATH=/app/models/random_forest_model.pkl \
    microservicio-grpc:1.0
```

### 3. Detener el Contenedor

```bash
docker stop wine-predictor
docker rm wine-predictor
```

## 📦 Dependencias Principales

```text
grpcio==1.54.2
grpcio-tools==1.54.2
numpy==1.24.3
scikit-learn==1.2.2
joblib==1.2.0
```

## 🔧 Variables de Entorno

- `GRPC_PORT`: Puerto para el servicio gRPC (default: 50051)
- `MODEL_PATH`: Ruta al modelo serializado (default: /app/models/random_forest_model.pkl)
- `PYTHONUNBUFFERED`: Configuración para logs de Python

## 🌟 Características del Servicio

- Predicción de calidad de vinos basada en características químicas
- Endpoint de health check para monitoreo
- Manejo de errores robusto
- Escalable y containerizado

## 📝 Uso del Servicio

1. Asegúrate de tener el modelo en la carpeta correcta:
```bash
mkdir -p models
# Coloca tu modelo random_forest_model.pkl en la carpeta models
```

2. Construir e iniciar el servicio:
```bash
# Desde la raíz del proyecto
docker build -t microservicio-grpc:1.0 -f docker/Dockerfile .
docker run -d --name wine-predictor -p 50051:50051 -v "$(pwd)/models:/app/models" microservicio-grpc:1.0
```

3. Probar el servicio:
```bash
cd src
python test_client.py
```

4. Detener el servicio:
```bash
docker stop wine-predictor
docker rm wine-predictor
```

## 🔍 Monitoreo

El servicio incluye un endpoint de health check que puede ser consultado para verificar:
- Estado del servicio
- Carga del modelo
- Mensajes de estado

## ⚠️ Consideraciones

- Asegúrate de que el modelo esté disponible en la ruta especificada
- El puerto 50051 debe estar disponible en el host
- Los permisos de ejecución deben estar configurados para los scripts .sh
```
