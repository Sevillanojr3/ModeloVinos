# Microservicio de Predicción de Vinos con gRPC

Este proyecto implementa un microservicio de predicción de vinos utilizando gRPC y se despliega en un clúster de Kubernetes (Minikube). El servicio utiliza un modelo de Machine Learning para predecir la calidad del vino basado en sus características químicas.

## Estructura del Proyecto

```
GRP/
├── docker/
│   ├── Dockerfile
│   ├── requirements.txt
│   ├── buildAll.sh
│   ├── runAll.sh
│   └── stopAll.sh
├── models/
│   └── random_forest_model.pkl
├── wine_service.proto
├── grp_app.py
├── test_client.py
├── wine_service_pb2.py
├── wine_service_pb2_grpc.py
├── docker-compose.yaml
└── k8s-grpc-deployment.yaml
```

## Componentes Principales

### 1. Definición del Servicio gRPC
El archivo `wine_service.proto` define la interfaz del servicio:
- `PredictWine`: Método para predecir la calidad del vino
- `CheckHealth`: Método para verificar el estado del servicio

### 2. Servidor gRPC
`grp_app.py` implementa la lógica del servidor:
- Carga el modelo de ML
- Procesa las solicitudes de predicción
- Proporciona health checks

### 3. Cliente de Prueba
`test_client.py` permite probar el servicio:
- Realiza health checks
- Envía solicitudes de predicción

### 4. Containerización

#### Docker
```bash
# Construir la imagen
cd docker
./buildAll.sh

# Ejecutar el contenedor
./runAll.sh

# Detener el contenedor
./stopAll.sh
```

#### Docker Compose
```bash
docker-compose up -d
```

### 5. Despliegue en Kubernetes

## Prerrequisitos

1. Instalar Minikube:
```bash
# Para Linux
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# Para MacOS
brew install minikube

# Para Windows (con chocolatey)
choco install minikube
```

2. Instalar kubectl:
```bash
# Para Linux
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# Para MacOS
brew install kubectl

# Para Windows (con chocolatey)
choco install kubernetes-cli
```

## Configuración Inicial

1. **Iniciar Minikube con recursos adecuados**:
```bash
minikube start --cpus 2 --memory 2048 --driver=docker
```

2. **Habilitar el registro local de Docker en Minikube**:
```bash
eval $(minikube docker-env)
```

3. **Construir la imagen Docker**:
```bash
cd ../docker
./buildAll.sh
```

4. **Crear directorio para modelos**:
```bash
minikube ssh
sudo mkdir -p /models
exit
```

5. **Copiar el modelo al directorio en Minikube**:
```bash
minikube cp ../models/random_forest_model.pkl /models/
```

## Despliegue

1. **Aplicar la configuración de Kubernetes**:
```bash
kubectl apply -f grpc.yaml
```

2. **Verificar el despliegue**:
```bash
# Verificar pods
kubectl get pods -w

# Verificar servicios
kubectl get services
```

3. **Exponer el servicio**:
```bash
minikube service wine-predictor-service --url
```

## Pruebas

1. **Configurar port-forwarding para pruebas locales**:
```bash
kubectl port-forward service/wine-predictor-service 50051:50051
```

2. **Ejecutar el cliente de prueba** (en otra terminal):
```bash
python ../test_client.py
```

## Monitoreo y Diagnóstico

```bash
# Ver logs de todos los pods
kubectl logs -l app=wine-predictor --all-containers=true -f

# Describir el deployment
kubectl describe deployment wine-predictor

# Ver eventos del cluster
kubectl get events --sort-by=.metadata.creationTimestamp
```

## Escalado

```bash
# Escalar manualmente
kubectl scale deployment wine-predictor --replicas=6

# Verificar el escalado
kubectl get pods -w
```

## Limpieza

```bash
# Eliminar el deployment y service
kubectl delete -f grpc.yaml

# Detener Minikube
minikube stop

# Eliminar el cluster (opcional)
minikube delete
```

## Solución de Problemas Comunes

1. **Los pods no inician**:
```bash
# Verificar eventos del pod
kubectl describe pod <nombre-del-pod>

# Verificar logs
kubectl logs <nombre-del-pod>
```

2. **Error de imagen no encontrada**:
- Asegúrate de haber construido la imagen con el registro de Docker de Minikube
- Verifica que estás usando `imagePullPolicy: Never` en el deployment

3. **Error de acceso al modelo**:
- Verifica que el modelo existe en `/models/` dentro de Minikube
- Comprueba los permisos del directorio

4. **Servicio no accesible**:
```bash
# Verificar endpoints
kubectl get endpoints wine-predictor-service

# Verificar service
kubectl describe service wine-predictor-service
```

## Comandos Útiles Adicionales

```bash
# Ver dashboard de Minikube
minikube dashboard

# Ver IP de Minikube
minikube ip

# Reiniciar deployment
kubectl rollout restart deployment wine-predictor

# Ver logs en tiempo real
kubectl logs -f deployment/wine-predictor
```

## Notas de Rendimiento

- El servicio está configurado para usar recursos mínimos (10m CPU, 50Mi memoria)
- Ajusta los recursos en `grpc.yaml` según tus necesidades
- Monitorea el uso de recursos con:
```bash
kubectl top pods
kubectl top nodes
```

## Configuración de Kubernetes

El archivo `k8s-grpc-deployment.yaml` define:

### Deployment
- 4 réplicas del servicio
- Estrategia RollingUpdate
- Recursos limitados:
  - Requests: CPU 10m, Memoria 50Mi
  - Límites: CPU 100m, Memoria 100Mi
- Health checks:
  - Liveness probe
  - Readiness probe

### Service
- Tipo NodePort
- Expone el puerto 50051

## Requisitos

- Docker
- Kubernetes/Minikube
- Python 3.10+
- gRPC
- scikit-learn

## Dependencias Python

```
grpcio==1.68.1
grpcio-tools==1.68.1
numpy==1.26.4
scikit-learn==1.4.1.post1
joblib==1.3.2
```

## Notas Importantes

1. Asegúrate de que el modelo ML esté disponible en la ruta correcta
2. El servicio requiere acceso al directorio de modelos
3. Los health checks deben estar implementados correctamente en el servidor gRPC
4. Los recursos asignados pueden necesitar ajustes según el uso

## Contribuciones

Las contribuciones son bienvenidas. Por favor, sigue estos pasos:
1. Fork el repositorio
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Crea un Pull Request
